{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f31742",
   "metadata": {},
   "source": [
    "# Task: Build a Mini Text-Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3d3c5",
   "metadata": {},
   "source": [
    "### Goal: Given a short paragraph of raw text, write a little script that:\n",
    "\n",
    "### Tokenizes the text into words.\n",
    "\n",
    "### Removes stop-words (use NLTK’s English stop-word list).\n",
    "\n",
    "### Applies stemming (Porter stemmer).\n",
    "\n",
    "### Counts word frequencies in the cleaned text.\n",
    "\n",
    "### Prints the top 5 most common stems and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "# 1. (Optional) Download NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "text = \"\"\"Your sample paragraph goes here: \n",
    "          e.g. “Natural Language Processing enables computers to understand human language.”\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tokenize\n",
    "tokens = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179474dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalize to lowercase\n",
    "tokens = [t.lower() for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461cce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Stem\n",
    "stemmer = PorterStemmer()\n",
    "stems = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Count frequencies\n",
    "freq = Counter(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a833aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Print top 5\n",
    "for stem, count in freq.most_common(5):\n",
    "    print(f\"{stem}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "# 1. (Optional) Download NLTK data (uncomment these lines if running for the first time)\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "text = \"\"\"Natural Language Processing (NLP) enables computers to understand, interpret, \n",
    "and generate human language in a valuable way. It sits at the intersection of computer \n",
    "science, artificial intelligence, and linguistics.\"\"\"\n",
    "\n",
    "# 2. Tokenize\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# 3. Normalize to lowercase\n",
    "tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "\n",
    "# 4. Remove stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered = [t for t in tokens if t not in stop_words]\n",
    "\n",
    "# 5. Stem\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(t) for t in filtered]\n",
    "\n",
    "# 6. Count frequencies\n",
    "freq = Counter(stems)\n",
    "\n",
    "# 7. Print top 5\n",
    "print(\"Top 5 stems:\")\n",
    "for stem, count in freq.most_common(5):\n",
    "    print(f\"{stem}: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
